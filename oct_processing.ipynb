{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we have downloaded a net CDF from the Copernicus Data Store: https://cds.climate.copernicus.eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  priogrid_gid  year\n",
      "0                0         62356  1980\n",
      "1                1         79599  1980\n",
      "2                2         79600  1980\n",
      "3                3         79601  1980\n",
      "4                4         80317  1980\n",
      "...            ...           ...   ...\n",
      "930805      930805        190496  2050\n",
      "930806      930806        190507  2050\n",
      "930807      930807        190508  2050\n",
      "930808      930808        190510  2050\n",
      "930809      930809        190511  2050\n",
      "\n",
      "[930810 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'month'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/gbenz/Documents/Climate Data/climate_extremes/oct_processing.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gbenz/Documents/Climate%20Data/climate_extremes/oct_processing.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(reference_df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gbenz/Documents/Climate%20Data/climate_extremes/oct_processing.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#print statement that summarizes the total number of rows appearing in the reference dataframe. \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/Climate%20Data/climate_extremes/oct_processing.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# ie. contains x total rows for y unique grid ideas and z until temporal elements\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/Climate%20Data/climate_extremes/oct_processing.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m reference_filtered_time \u001b[39m=\u001b[39m reference_df\u001b[39m.\u001b[39mloc[\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gbenz/Documents/Climate%20Data/climate_extremes/oct_processing.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         ((reference_df[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mint\u001b[39m(loc_start_year)) \u001b[39m&\u001b[39m (reference_df[\u001b[39m'\u001b[39;49m\u001b[39mmonth\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(loc_start_month))) \u001b[39m&\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/Climate%20Data/climate_extremes/oct_processing.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         ((reference_df[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mint\u001b[39m(loc_end_year)) \u001b[39m&\u001b[39m (reference_df[\u001b[39m'\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(loc_end_month)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/Climate%20Data/climate_extremes/oct_processing.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/Climate%20Data/climate_extremes/oct_processing.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(reference_filtered_time)\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'month'"
     ]
    }
   ],
   "source": [
    "loc_start_year = '2015'\n",
    "loc_start_month = '01'\n",
    "loc_end_year = '2015'\n",
    "loc_end_month = '03'\n",
    "\n",
    "reference_df = pd.read_csv('data/processed/reference_table/pg___y.csv')\n",
    "print(reference_df)\n",
    "\n",
    "#print statement that summarizes the total number of rows appearing in the reference dataframe. \n",
    "    # ie. contains x total rows for y unique grid ideas and z until temporal elements\n",
    "\n",
    "\n",
    "reference_filtered_time = reference_df.loc[\n",
    "        ((reference_df['year'] == int(loc_start_year)) & (reference_df['month'] >= int(loc_start_month))) &\n",
    "        ((reference_df['year'] == int(loc_end_year)) & (reference_df['month'] <= int(loc_end_month)))\n",
    "    ]\n",
    "print(reference_filtered_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      int64\n",
      "priogrid_gid    int64\n",
      "year            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(reference_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Changes:\n",
    "\n",
    "- The complete table should be saved in the directory: `data/generated/index_table_output`\n",
    "    - The file name must include the start and end dates for easier identification.\n",
    "\n",
    "- For the functions `generate_etccdi_temporal_tables` and `generate_etccdi_temporal_tables__centroid`:\n",
    "    - Suppress the printing of each graphic iteration during execution to reduce unnecessary output.\n",
    "\n",
    "- Ensure that all generated graphics reference a single, consistent scale (legend).\n",
    "\n",
    "- Issue with validation if:\n",
    "    - partial years are set in the parameters option \n",
    "    - ex. monthly data is allowed but parameters request only part of given year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do List\n",
    "\n",
    "## Decision Tree Development\n",
    "- Create a **decision tree for defensible methods** based on different applications:\n",
    "    - If performing at an admin or country scale, use method X.\n",
    "    - Address the question: \"At what scale does the utility of finer-grained PRIOgrid data diminish?\" \n",
    "    - Incorporate considerations of 'other' shapefile extents.\n",
    "\n",
    "## API Considerations\n",
    "- Investigate potential **API changes**:\n",
    "    1. Ensure the `define_request.py` script is correctly referenced.\n",
    "    2. Contact CDS to determine their API update schedule (e.g., every 6 months or yearly).\n",
    "    3. Check the **CDS API forum** for transparency on updates.\n",
    "\n",
    "## Feature Enhancements\n",
    "- Add **descriptive statistics**:\n",
    "    - Include basic summary stats for the requested indices.\n",
    "- Allow users to view country-specific data:\n",
    "    - Avoid packaging into larger datasets.\n",
    "  \n",
    "## Additional Notes\n",
    "- Add a **section in the documentation** clarifying how to migrate workflows smoothly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utils path added to Python Path: /Users/gbenz/Documents/Climate Data/climate_extremes/utils\n"
     ]
    }
   ],
   "source": [
    "from setup_environment import setup_utils_path\n",
    "setup_utils_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Format API Request ----------------------------------------------------------------\n",
    "from unzip import unzip_etccdi_package\n",
    "from correct_longitude import transform_longitudinal_values\n",
    "from temporal_index import find_etccdi_timeindex, translate_index_to_daterange\n",
    "from define_request import generate_and_validate_request\n",
    "\n",
    "# Provide Metadata ------------------------------------------------------------------\n",
    "from give_metadata import give_metadata\n",
    "\n",
    "# Build API Request -----------------------------------------------------------------\n",
    "from cds_api_pull import pull_from_cds_api\n",
    "\n",
    "# Methods ---------------------------------------------------------------------------\n",
    "from etccdi_to_pg__pointquery import generate_etccdi_temporal_tables__centroid\n",
    "from etccdi_to_pg import generate_etccdi_temporal_tables\n",
    "\n",
    "# Validation ------------------------------------------------------------------------\n",
    "from give_reference_frame import provide_reference_frame\n",
    "from id_null_values import report_null_etccdi_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access with Copernicus Data Store API:\n",
    "\n",
    "### You must have both a Copernicus Data Store account and have followed the proceeding instructions on setting up the CDSAPI before you can retrieve and process data from this toolbox. \n",
    "\n",
    "#### The following instructions reference the CDSAPI set up guide: https://cds.climate.copernicus.eu/how-to-api\n",
    "\n",
    "\n",
    "The final objective is to construct a main.py function that accepts the parameters below and automatically computes the process!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Request and Processing Parameters\n",
    "\n",
    "### API Request Parameters\n",
    "These parameters define the data retrieved via the API request:\n",
    "- **`variable`**: Specifies the data variable of interest.\n",
    "- **`product_type`**: Indicates the base product type.\n",
    "- **`experiment`**: Defines the experimental setup or scenario.\n",
    "- **`temporal_aggregation`**: Determines the temporal resolution of the data.\n",
    "\n",
    "### Processing Parameters\n",
    "These parameters guide the processing workflow:\n",
    "- **`start_year`**: `'1995'`\n",
    "- **`start_month`**: `'01'`\n",
    "- **`end_year`**: `'2000'`\n",
    "- **`end_month`**: `'12'`\n",
    "\n",
    "### Method Selection\n",
    "Choose a resampling or data alignment method:\n",
    "- **Bilinear sampling**: Applies weighted interpolation for smoother results.\n",
    "- **Point neighbor**: Maps the closest neighboring value preserving the original coarse resolution.\n",
    "\n",
    "### (In Development) Extent Selection\n",
    "Additional options for spatial analysis:\n",
    "- Empirical distributions based on basin-specific extents.\n",
    "- Future iterations will enable a 'hotspot' methodology for comparison with global metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of CDS Request\n",
    "\n",
    "```\n",
    "import cdsapi\n",
    "\n",
    "dataset = \"sis-extreme-indices-cmip6\"\n",
    "request = {\n",
    "    \"variable\": [\"cold_days\"], \n",
    "    \"product_type\": [\"base_period_1961_1990\"],\n",
    "    \"model\": [\"hadgem3_gc31_ll\"],\n",
    "    \"ensemble_member\": [\"r1i1p1f3\"],\n",
    "    \"experiment\": [\"ssp1_2_6\"],\n",
    "    \"temporal_aggregation\": [\"monthly\"],\n",
    "    \"period\": [\"201501_210012\"],\n",
    "    \"version\": [\"2_0\"]\n",
    "}\n",
    "\n",
    "client = cdsapi.Client()\n",
    "client.retrieve(dataset, request).download()\n",
    "```   \n",
    "``` \n",
    "dataset = \"sis-extreme-indices-cmip6\"\n",
    "request = {\n",
    "    \"variable\": [\"consecutive_dry_days\"],\n",
    "    \"product_type\": [\"base_independent\"],\n",
    "    \"model\": [\"hadgem3_gc31_ll\"],\n",
    "    \"ensemble_member\": [\"r1i1p1f3\"],\n",
    "    \"experiment\": [\"ssp1_2_6\"],\n",
    "    \"temporal_aggregation\": [\"yearly\"],\n",
    "    \"period\": [\"2015_2100\"],\n",
    "    \"version\": [\"2_0\"]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Type and Variable Temporal Aggregation\n",
    "\n",
    "| product_type            | variable                           | temporal_aggregation |\n",
    "|-------------------------|------------------------------------|----------------------|\n",
    "| base_independent         | consecutive_dry_days               | annual               |\n",
    "| base_independent         | consecutive_wet_days               | annual               |\n",
    "| base_independent         | diurnal_temperature_range          | monthly or annual    |\n",
    "| base_independent         | frost_days                         | annual               |\n",
    "| base_independent         | growing_season_length              | annual               |\n",
    "| base_independent         | heavy_precipitation_days           | annual               |\n",
    "| base_independent         | ice_days                           | annual               |\n",
    "| base_independent         | maximum_1_day_precipitation        | monthly or annual    |\n",
    "| base_independent         | maximum_5_day_precipitation        | monthly or annual    |\n",
    "| base_independent         | maximum_value_of_daily_maximum_temperature | monthly or annual    |\n",
    "| base_independent         | minimum_value_of_daily_maximum_temperature | monthly or annual    |\n",
    "| base_independent         | maximum_value_of_daily_minimum_temperature | monthly or annual    |\n",
    "| base_independent         | minimum_value_of_daily_minimum_temperature | monthly or annual    |\n",
    "| base_independent         | number_of_wet_days                 | annual               |\n",
    "| base_independent         | simple_daily_intensity_index       | annual               |\n",
    "| base_independent         | summer_days                        | annual               |\n",
    "| base_independent         | total_wet_day_precipitation        | annual               |\n",
    "| base_independent         | tropical_nights                    | annual               |\n",
    "| base_independent         | very_heavy_precipitation_days      | annual               |\n",
    "| base_period_1961_1990    | cold_days                          | monthly or annual    |\n",
    "| base_period_1961_1990    | cold_nights                        | monthly or annual    |\n",
    "| base_period_1961_1990    | warm_days                          | monthly or annual    |\n",
    "| base_period_1961_1990    | warm_nights                        | monthly or annual    |\n",
    "\n",
    "The table above defines the `product_type`, `variable`, and the corresponding `temporal_aggregation` classification options for required parameters. Variables that are only available on a yearly basis are labeled as \"annual,\" while others that can be reported on both monthly and annual bases are labeled as \"monthly or annual.\"\n",
    "\n",
    "### Experiment Period Mapping\n",
    "\n",
    "| experiment  | period        |\n",
    "|-------------|---------------|\n",
    "| historical | 185001_201412 |\n",
    "| ssp1_2_6   | 201501_210012 |\n",
    "| SSP2_4_5   | 201501_210012 |\n",
    "| SSP5_8_5   | 201501_210012 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_variable = \"consecutive_dry_days\"\n",
    "p_product_type=\"base_independent\"\n",
    "p_experiment=\"ssp1_2_6\"\n",
    "p_temporal_aggregation=\"yearly\"\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Define Start Year & Month\n",
    "#-----------------------------------------------------------\n",
    "start_year = '2015'\n",
    "start_month = '01'\n",
    "#-----------------------------------------------------------\n",
    "# Define End Year & Month\n",
    "end_year = '2018'\n",
    "end_month = '04'\n",
    "#-----------------------------------------------------------\n",
    "method = 'resample'\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "#country_selection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request is valid.\n",
      "yearly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'variable': ['consecutive_dry_days'],\n",
       " 'product_type': ['base_independent'],\n",
       " 'model': ['hadgem3_gc31_ll'],\n",
       " 'ensemble_member': ['r1i1p1f3'],\n",
       " 'experiment': ['ssp1_2_6'],\n",
       " 'temporal_aggregation': ['yearly'],\n",
       " 'period': ['2015_2100'],\n",
       " 'version': ['2_0'],\n",
       " 'data_format': 'netcdf'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priogrid_gid     int64\n",
      "year            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Now, calling the function will generate and validate the request\n",
    "\n",
    "request = generate_and_validate_request(\n",
    "    variable=p_variable,\n",
    "    product_type=p_product_type,\n",
    "    experiment=p_experiment,\n",
    "    temporal_aggregation=p_temporal_aggregation\n",
    ")\n",
    "temporal_aggregation_value = request['temporal_aggregation'][0]\n",
    "print(temporal_aggregation_value)\n",
    "display(request)\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "# Load a clean PG dataframe at a consistent temporal resolution\n",
    "# to the request built\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "reference_df = provide_reference_frame(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zip_file_name will appear in folder:\n",
    "\n",
    "```\n",
    "CLIMATE_EXTREMES/\n",
    "├── data/\n",
    "│   ├── raw_external/\n",
    "│   │   └── cds_zip/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 10:40:03,199 WARNING [2024-11-19T00:00:00] Issue with underlaying infrastructure is now solved. System should gradually recover. Please check updated status [here](https://status.ecmwf.int/)\n",
      "2024-11-20 10:40:03,200 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n",
      "2024-11-20 10:40:03,200 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2024-11-20 10:40:03,200 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n",
      "2024-11-20 10:40:03,201 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2024-11-20 10:40:03,501 INFO Request ID is dce7ecbc-48a3-4ce4-9821-2b7b4297d045\n",
      "2024-11-20 10:40:03,585 INFO status has been updated to accepted\n",
      "2024-11-20 10:40:06,385 INFO status has been updated to running\n",
      "2024-11-20 10:40:08,725 INFO status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3b1f7f4c9146f1a63d7de4b4962fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "f4cdbbeb7b9a6be0ebf300021c1e85a7.zip:   0%|          | 0.00/9.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zip_file_name = pull_from_cds_api(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The netcdf file will appear in folder: \n",
    "\n",
    "```\n",
    "CLIMATE_EXTREMES/\n",
    "├── data/\n",
    "│   ├── generated/\n",
    "│   │   └── netcd/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cddETCCDI\n",
      "Extracted file names: cddETCCDI_yr_HadGEM3-GC31-LL_ssp126_r1i1p1f3_no-base_v20200114_2015-2100_v2-0.nc\n"
     ]
    }
   ],
   "source": [
    "netcdf_file, etccdi_index = unzip_etccdi_package(zip_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted netcdf file replaced the original file in location:\n",
    "\n",
    "```\n",
    "CLIMATE_EXTREMES/\n",
    "├── data/\n",
    "│   ├── generated/\n",
    "│   │   └── netcd/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variable 'cddETCCDI' was found in the file path and the world continues to spin.\n",
      "Original Latitude range: -89.375 to 89.375\n",
      "Original Longitude range: 0.9375 to 359.0625\n",
      "Adjusted Longitude range: -179.0625 to 179.0625\n",
      "Adjusted dataset saved to: /Users/gbenz/Documents/Climate Data/climate_extremes/data/generated/netcdf/adjusted_cddETCCDI_yr_HadGEM3-GC31-LL_ssp126_r1i1p1f3_no-base_v20200114_2015-2100_v2-0.nc.nc\n"
     ]
    }
   ],
   "source": [
    "etccdi = transform_longitudinal_values(etccdi_index, netcdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude range: -89.375 to 89.375\n",
      "Longitude range: -179.0625 to 179.0625\n",
      "Latitude resolution: 1.25\n",
      "Longitude resolution: 1.875\n",
      "Global Metadata:\n",
      "CDI: Climate Data Interface version 1.8.0 (http://mpimet.mpg.de/cdi)\n",
      "history: Tue Nov 24 09:31:53 2020: cdo mergetime tasmax_day_HadGEM3-GC31-LL_ssp126_r1i1p1f3_gn_20150101-20491230.nc tasmax_day_HadGEM3-GC31-LL_ssp126_r1i1p1f3_gn_20500101-21001230.nc ./merged/tasmax_day_HadGEM3-GC31-LL_ssp126_r1i1p1f3_gn_20150101-21001230.nc\n",
      "2020-01-13T09:55:40Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.;\n",
      "2020-01-13T09:53:59Z MIP Convert v1.2.3, Python v2.7.12, Iris v1.13.0, Numpy v1.13.3, netcdftime v1.4.1.\n",
      "source: HadGEM3-GC31-LL (2016): \n",
      "aerosol: UKCA-GLOMAP-mode\n",
      "atmos: MetUM-HadGEM3-GA7.1 (N96; 192 x 144 longitude/latitude; 85 levels; top level 85 km)\n",
      "atmosChem: none\n",
      "land: JULES-HadGEM3-GL7.1\n",
      "landIce: none\n",
      "ocean: NEMO-HadGEM3-GO6.0 (eORCA1 tripolar primarily 1 deg with meridional refinement down to 1/3 degree in the tropics; 360 x 330 longitude/latitude; 75 levels; top grid cell 0-1 m)\n",
      "ocnBgchem: none\n",
      "seaIce: CICE-HadGEM3-GSI8 (eORCA1 tripolar primarily 1 deg; 360 x 330 longitude/latitude)\n",
      "institution: Met Office Hadley Centre, Fitzroy Road, Exeter, Devon, EX1 3PB, UK\n",
      "Conventions: CF-1.7 CMIP-6.2\n",
      "activity_id: ScenarioMIP\n",
      "branch_method: standard\n",
      "branch_time_in_child: 59400.0\n",
      "branch_time_in_parent: 59400.0\n",
      "input_creation_date: 2020-01-13T10:10:01Z\n",
      "cv_version: 6.2.37.5\n",
      "data_specs_version: 01.00.29\n",
      "experiment: update of RCP2.6 based on SSP1\n",
      "experiment_id: ssp126\n",
      "external_variables: areacella\n",
      "forcing_index: 3\n",
      "input_frequency: day\n",
      "further_info_url: https://furtherinfo.es-doc.org/CMIP6.MOHC.HadGEM3-GC31-LL.ssp126.none.r1i1p1f3\n",
      "grid: Native N96 grid; 192 x 144 longitude/latitude\n",
      "grid_label: gn\n",
      "initialization_index: 1\n",
      "institution_id: MOHC\n",
      "mip_era: CMIP6\n",
      "mo_runid: u-bj611\n",
      "nominal_resolution: 250 km\n",
      "parent_activity_id: CMIP\n",
      "parent_experiment_id: historical\n",
      "parent_mip_era: CMIP6\n",
      "parent_source_id: HadGEM3-GC31-LL\n",
      "parent_time_units: days since 1850-01-01\n",
      "parent_variant_label: r1i1p1f3\n",
      "physics_index: 1\n",
      "product: model-output\n",
      "realization_index: 1\n",
      "realm: atmos\n",
      "source_id: HadGEM3-GC31-LL\n",
      "source_type: AOGCM AER\n",
      "sub_experiment: none\n",
      "sub_experiment_id: none\n",
      "table_id: day\n",
      "table_info: Creation Date:(13 December 2018) MD5:f0588f7f55b5732b17302f8d9d0d7b8c\n",
      "input_title: HadGEM3-GC31-LL output prepared for CMIP6\n",
      "input_tracking_id: hdl:21.14100/8e91bf77-1c96-4585-b92c-c438a87d4135\n",
      "variable_id: tasmax\n",
      "variable_name: tasmax\n",
      "variant_label: r1i1p1f3\n",
      "license: CMIP6 model data produced by the Met Office Hadley Centre is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file) and at https://ukesm.ac.uk/cmip6. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.\n",
      "cmor_version: 3.4.0\n",
      "CDO: Climate Data Operators version 1.8.0 (http://mpimet.mpg.de/cdo)\n",
      "ETCCDI_institution: Center for International Climate and Environmental Research - Oslo, Norway\n",
      "ETCCDI_institution_id: CICERO\n",
      "ETCCDI_software: climdex.pcic\n",
      "ETCCDI_software_version: 1.1.9.1\n",
      "frequency: yr\n",
      "creation_date: 2020-11-27T13:08:03Z\n",
      "title: ETCCDI indices computed on HadGEM3-GC31-LL output prepared for CMIP6\n",
      "Unique Years: [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100]\n",
      "Unique Months: [6]\n"
     ]
    }
   ],
   "source": [
    "give_metadata(etccdi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include month attribute on pg__m.csv reference sheet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for 01 of the year 2015 but located data for the first available month.\n",
      "Validation: Found data for Year: 2015, Month: 06 at index 0.\n",
      "\n",
      "No data found for 04 of the year 2018 but located data for the first available month.\n",
      "Validation: Found data for Year: 2018, Month: 06 at index 3.\n",
      "\n",
      "The start index is: 0, referencing Month: 06 and Year: 2015\n",
      "\n",
      "The end index is: 3, referencing Month: 06 and Year: 2018\n",
      "\n",
      "        priogrid_gid  year\n",
      "458850         62356  2015\n",
      "458851         79599  2015\n",
      "458852         79600  2015\n",
      "458853         79601  2015\n",
      "458854         80317  2015\n",
      "...              ...   ...\n",
      "511285        190496  2018\n",
      "511286        190507  2018\n",
      "511287        190508  2018\n",
      "511288        190510  2018\n",
      "511289        190511  2018\n",
      "\n",
      "[52440 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "index_list, reference_filtered_time = translate_index_to_daterange(etccdi, reference_df, temporal_aggregation_value, start_year, start_month, end_year, end_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params:\n",
    "\n",
    "- time_index_list,\n",
    "- netcdf, climate_index, \n",
    "- shapefile_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Raster files:\n",
    "```\n",
    "CLIMATE_EXTREMES/\n",
    "├── data/\n",
    "│   ├── generated/\n",
    "│   │   └── index_raster_output/\n",
    "```\n",
    "\n",
    "Final output table:\n",
    "```\n",
    "CLIMATE_EXTREMES/\n",
    "├── data/\n",
    "│   ├── generated/\n",
    "│   │   └── index_table_output/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_filename = generate_etccdi_temporal_tables__centroid(index_list, etccdi, etccdi_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_filename = generate_etccdi_temporal_tables(index_list, etccdi, etccdi_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``translated_filename`` retrieves the summary table saved to:\n",
    "\n",
    "\n",
    "``reference_filtered_time`` retrieves the primary reference table saved to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_null_etccdi_values(translated_filename, reference_filtered_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now you can migrate to the ingestion script\n",
    "\n",
    "We want to intentionally keep these things seperate (lock / key) so unwanted things are not automatically ingested\n",
    "\n",
    "- **Clarify migration to the ingestion script**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Now you are ready to run the ingestion code located in .... \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
